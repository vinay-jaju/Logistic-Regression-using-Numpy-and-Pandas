{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(data_file,test=False):\n",
    "    '''\n",
    "    This reads inputs files and assigns column names since the data has no column names.\n",
    "    Skipping initial space since the data has space which makes difficult to get values by names.\n",
    "    Column names: [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
    "        \n",
    "    Args:\n",
    "    * data_file: Input file path\n",
    "    * test=False; This takes care of skipping initial row in case of test data. The test data is like that.\n",
    "    \n",
    "    Return:\n",
    "    Dataframe with proper column names\n",
    "    '''\n",
    "    columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\", \n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\", \"income_bracket\"]\n",
    "    if test:\n",
    "        df = pd.read_csv(data_file,names=columns,skipinitialspace=True,skiprows=1)\n",
    "    else:\n",
    "        df = pd.read_csv(data_file,names=columns,skipinitialspace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary(x):\n",
    "    '''\n",
    "    Reduces categories ['1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th'] and makes it \"Primary\"\n",
    "        \n",
    "    Args:\n",
    "    * x: String\n",
    "    \n",
    "    Return:\n",
    "    \"Primary\"/ x\n",
    "    '''\n",
    "    if x in ['1st-4th', '5th-6th', '7th-8th', '9th', '10th', '11th', '12th']:\n",
    "        return ' Primary'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def native(country):\n",
    "    '''\n",
    "    Grouping countries based on region\n",
    "    Args:\n",
    "    * x: Country Name\n",
    "    \n",
    "    Return:\n",
    "    Region for country\n",
    "\n",
    "    '''\n",
    "    if country in ['United-States',  'Unknown','Canada','Columbia']:\n",
    "        return 'North America'\n",
    "    elif country in ['Cuba','Mexico','Dominican-Republic','Puerto-Rico','Outlying-US(Guam-USVI-etc)','Jamaica','Haiti'\n",
    "                     ,'Honduras','El-Salvador','Guatemala','Nicaragua']:\n",
    "        return 'Central America'\n",
    "    elif country in ['South','Ecuador','Peru','Trinadad&Tobago']:\n",
    "        return 'South America'\n",
    "    elif country in ['England', 'Germany','Italy','Portugal','France', 'Yugoslavia','Scotland','Greece', \n",
    "                     'Ireland',' Philippines','Hungary','Holand-Netherlands','Ireland','Poland']:\n",
    "        return 'European'\n",
    "    elif country in ['India', 'Iran', 'Philippines','Cambodia','Thailand', 'Laos', 'Taiwan', 'Japan', 'China', 'Vietnam',\n",
    "                     'Hong']:\n",
    "        return 'Eastern'    \n",
    "    else: \n",
    "        return country "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    '''\n",
    "    data: dataframe which you want to normalize\n",
    "    returns: normalized dataframe and normalization params\n",
    "    '''\n",
    "    fmean=np.mean(data)\n",
    "    frange=np.amax(data)-np.amin(data)\n",
    "    normalization_params = [fmean,frange]\n",
    "    data-=fmean\n",
    "    data/=frange\n",
    "    return data,normalization_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train(df):\n",
    "    '''\n",
    "    This is a helper function which is developed using the analysis done.\n",
    "    '''\n",
    "    df.replace('?',np.nan,inplace=True)\n",
    "    df['workclass'].fillna('Not working now', inplace=True)\n",
    "    df['occupation'].fillna('Unknown',inplace=True)\n",
    "    df['native_country'].fillna('Unknown',inplace=True)\n",
    "    #df['income_bracket'] = df['income_bracket'].apply(lambda x: 1 if x=='>50K' else 0)\n",
    "    df['education'] = df['education'].apply(primary)\n",
    "    df['fnlwgt'] = df['fnlwgt'].apply(lambda x: np.log1p(x))\n",
    "    df['native_country']=df['native_country'].apply(lambda country: native(country))\n",
    "    df=pd.get_dummies(df)\n",
    "    df,normalization_params=normalize(df)\n",
    "    return df,normalization_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test(df,normalization_params):\n",
    "    '''\n",
    "    This is a helper function which is developed using the analysis done.\n",
    "    '''\n",
    "    df.replace('?',np.nan,inplace=True)\n",
    "    df['workclass'].fillna('Not working now', inplace=True)\n",
    "    df['occupation'].fillna('Unknown',inplace=True)\n",
    "    df['native_country'].fillna('Unknown',inplace=True)\n",
    "    #df['income_bracket'] = df['income_bracket'].apply(lambda x: 1 if x=='>50K' else 0)\n",
    "    df['education'] = df['education'].apply(primary)\n",
    "    df['fnlwgt'] = df['fnlwgt'].apply(lambda x: np.log1p(x))\n",
    "    df['native_country']=df['native_country'].apply(lambda country: native(country))\n",
    "    df=pd.get_dummies(df)\n",
    "    #normalizing\n",
    "    fmean,frange=normalization_params\n",
    "    df-=fmean\n",
    "    df/=frange\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightInitialization(n_features):\n",
    "    w = np.zeros((1,n_features))\n",
    "    b = 0\n",
    "    return w,b\n",
    "\n",
    "def sigmoid_activation(result):\n",
    "    final_result = 1/(1+np.exp(-result))\n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_optimize(w, b, X, Y):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #Prediction\n",
    "    final_result = sigmoid_activation(np.dot(w,X.T)+b)\n",
    "    Y_T = Y.T\n",
    "    cost = (-1/m)*(np.sum((Y_T*np.log(final_result)) + ((1-Y_T)*(np.log(1-final_result)))))\n",
    "    #\n",
    "    \n",
    "    #Gradient calculation\n",
    "    dw = (1/m)*(np.dot(X.T, (final_result-Y.T).T))\n",
    "    db = (1/m)*(np.sum(final_result-Y.T))\n",
    "    \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(w, b, X, Y, learning_rate, no_iterations):\n",
    "    costs = []\n",
    "    for i in range(no_iterations):\n",
    "        #\n",
    "        grads, cost = model_optimize(w,b,X,Y)\n",
    "        #\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        #weight update\n",
    "        w = w - (learning_rate * (dw.T))\n",
    "        b = b - (learning_rate * db)\n",
    "        #\n",
    "        \n",
    "        if (i % 100 == 0):\n",
    "            costs.append(cost)\n",
    "            print(\"Cost after %i iteration is %f\" %(i, cost))\n",
    "    \n",
    "    #final parameters\n",
    "    coeff = {\"w\": w, \"b\": b}\n",
    "    gradient = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return coeff, gradient, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToClasses(final_pred, m):\n",
    "    y_pred = np.zeros((1,m))\n",
    "    for i in range(final_pred.shape[1]):\n",
    "        if final_pred[0][i] > 0.5:\n",
    "            y_pred[0][i] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
    "    # Compute accuracy for each possible representation\n",
    "    score = y_true == y_pred\n",
    "\n",
    "    return np.average(score, weights=sample_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_file(data_file, iters):\n",
    "    \"\"\"Trains a logisitc regression classifier.\n",
    "\n",
    "  Args:\n",
    "    data_file: a path to a csv file containing training data, without headers.\n",
    "    iters: the number of iterations to use when training the classifier\n",
    "\n",
    "  Returns:\n",
    "    weights: a column vector (1d numpy array) containing the weights learned in your classifier.\n",
    "    normalization_params: a dict mapping column names to (min, max) values from the training set\n",
    "  \"\"\"\n",
    "    df=read_input(data_file)\n",
    "    #xtrain and y_train\n",
    "    X_train= df.drop('income_bracket', axis=1)\n",
    "    y_train = df['income_bracket'].apply(lambda x: 1 if x=='>50K' else 0)\n",
    "    \n",
    "    #preprocess\n",
    "    X_train,normalization_params=preprocess_train(X_train)\n",
    "\n",
    "    n_features = X_train.shape[1]\n",
    "    print('Number of Features', n_features)\n",
    "    w, b = weightInitialization(n_features)\n",
    "   \n",
    "    #Gradient Descent\n",
    "    coeff, gradient, costs = model_train(w, b, X_train.values, y_train.values, learning_rate=0.001,no_iterations=iters)\n",
    "    #weights=coeff\n",
    "    #print(coeff['w'])\n",
    "    #print(coeff['b'])\n",
    "    m_tr =  X_train.shape[0]\n",
    "    final_train_pred = sigmoid_activation(np.dot(w,X_train.values.T)+b)\n",
    "    labels = np.round(final_train_pred,0)\n",
    "    y_tr_pred = convertToClasses(final_train_pred, m_tr)\n",
    "    #print('Training Accuracy',accuracy_score(y_tr_pred.T, y_train.values))\n",
    "    return coeff, normalization_params\n",
    "    \n",
    "def classify(data_file, weights, normalization_params):\n",
    "    \"\"\"Classifies data based on the supplied logistic regression weights.\n",
    "\n",
    "    Args:\n",
    "    data_file: a path to a csv file containing test data, without headers.\n",
    "    weights: a column vectors containing the weights learned during training.\n",
    "    normalization_params: a dict mapping column names to (min, max) values from the training set\n",
    "\n",
    "    Returns:\n",
    "    a column vector containing either a 1 or a 0 for each row in data_file\n",
    "    \"\"\"\n",
    "    test=read_input(data_file,True)\n",
    "    X_test = test.drop('income_bracket', axis=1)\n",
    "    y_test = test['income_bracket'].apply(lambda x: 1 if x=='>50K.' else 0)\n",
    "    X_test=preprocess_test(X_test,normalization_params)\n",
    "    w = weights[\"w\"]\n",
    "    b = weights[\"b\"]\n",
    "    final_test_pred = sigmoid_activation(np.dot(w,X_test.values.T)+b)\n",
    "    m_ts =  test.shape[0]\n",
    "    labels = convertToClasses(final_test_pred, m_ts)\n",
    "    print('Test Accuracy',accuracy_score(labels.T, y_test.values))\n",
    "    return labels\n",
    "\n",
    "# Our grading program will use these functions as follows:\n",
    "def sample_main():\n",
    "    weights, normalization_params = train_with_file('adult-training.csv', 1000)\n",
    "    labels = classify('adult-test.csv', weights, normalization_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features 65\n",
      "Cost after 0 iteration is 0.693147\n",
      "Cost after 100 iteration is 0.683225\n",
      "Cost after 200 iteration is 0.673746\n",
      "Cost after 300 iteration is 0.664690\n",
      "Cost after 400 iteration is 0.656037\n",
      "Cost after 500 iteration is 0.647767\n",
      "Cost after 600 iteration is 0.639861\n",
      "Cost after 700 iteration is 0.632301\n",
      "Cost after 800 iteration is 0.625071\n",
      "Cost after 900 iteration is 0.618152\n",
      "Test Accuracy 0.7555758550254775\n",
      "Wall time: 5.92 s\n"
     ]
    }
   ],
   "source": [
    "%time sample_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# df=read_input('adult-training.csv')\n",
    "# #xtrain and y_train\n",
    "# X_train= df.drop('income_bracket', axis=1)\n",
    "# y_train = df['income_bracket'].apply(lambda x: 1 if x=='>50K' else 0)\n",
    "\n",
    "# #preprocess\n",
    "# X_train,normalization_params=preprocess_train(X_train)\n",
    "# model=LogisticRegression()\n",
    "# model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# test=read_input('adult-test.csv',True)\n",
    "# X_test = test.drop('income_bracket', axis=1)\n",
    "# y_test = test['income_bracket'].apply(lambda x: 1 if x=='>50K.' else 0)\n",
    "# X_test=preprocess_test(X_test,normalization_params)\n",
    "\n",
    "# y_test_pred=model.predict(X_test)\n",
    "\n",
    "# print(\"Accuracy using Scikit learn is \"accuracy_score(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
